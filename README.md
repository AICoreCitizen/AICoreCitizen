# Welcome to Abraham's AICore Bootcamp Data Engineering Repository âœ¨

Greetings, fellow enthusiasts! ðŸ‘‹ Dive into the heart of data engineering excellence with me on the AICore Bootcamp's Data Engineering Specialist path. This repository serves as a dynamic showcase of the comprehensive journey undertaken through various modules, each contributing to a robust skill set in the realm of data engineering.

```python
abs = {
    'name': 'Abraham Audu',
    'location': 'London, UK',
    'bootcamp computer languages': ['python', 'SQL', 'json', 'yaml'],
    'aws cloud services': ['cli', 'ec2', 's3', 'iam', 'amazon rds', 'kafka', 'spark', 'airflow', 'databricks', 'kinesis'],
    'profession': ['senior consultant', 'technical program manager']
}
```
[![LinkedIn](https://onedrive.live.com/embed?resid=A2D9CDEC6C07694B%21312296&authkey=%21ADPWtzaMqQH_6n0&width=48&height=48)](https://www.linkedin.com/in/abraham-audu-39ba8927/)
[![Twitter](https://onedrive.live.com/embed?resid=A2D9CDEC6C07694B%21312391&authkey=%21ANFnY3forRc5Olc&width=48&height=48)](https://twitter.com/abraham_audu_7)
[![Github](https://onedrive.live.com/embed?resid=A2D9CDEC6C07694B%21312252&authkey=%21AI_zh6e5JeF8zfA&width=48&height=48)](https://github.com/ReturnOfAbs)

## Purpose of the Repository

Here, you'll find a meticulously curated collection of projects, exercises, and insights crafted during the completion of the AICore Bootcamp's Data Engineering Specialist path. Let's take a peek at the modules that will shape this repository:

### Module 1: Data Formats and Processing Libraries
- Exploring JSON, CSV, XLSX, and YAML
- Tabular Data and Pandas Dataframes
- Advanced Dataframe Operations and Data Cleaning in Pandas
- Numpy and Handling Missing Data

### Module 2: Web APIs
- Basics of APIs and Communication Protocols
- Working with API Requests
- FastAPI: Routing and Sending Data

### Module 3: SQL
- SQL fundamentals and best practices
- CRUD Operations and SQL JOINs
- Common Aggregations and Subqueries
- Working with pyscopg2 and SQLAlchemy

### Module 4: Essential Cloud Technology
- Understanding Cloud Concepts
- AWS IAM and CLI
- Introduction to Amazon S3 and EC2
- Exploring Virtual Private Cloud and IAM Roles
- Amazon RDS and Billing in AWS

### Module 5: Big Data Engineering Foundations
- Navigating the Data Engineering Landscape
- Data Pipelines, Ingestion, and Storage
- Understanding Batch vs Real-Time Processing
- Handling Structured, Unstructured, and Complex Data

### Module 6: Data Ingestion
- Principles of Data Ingestion
- Batch and Real-Time Data Processing
- Exploring Kafka Essentials and Kafka-Python
- Streaming in Kafka

### Module 7: Data Wrangling and Transformation
- ELT & ETL Data Transformations
- Apache Spark and Pyspark
- Distributed Processing with Spark
- Integrating Spark with Kafka and AWS S3
- Spark Streaming

### Module 8: Data Orchestration
- Exploring Apache Airflow
- Integrating Airflow with Spark

### Module 9: Advanced Cloud Technologies and Databricks
- Understanding MSK and MSK Connect
- AWS API Gateway and Integration with Kafka
- Databricks Essentials and Integration with Amazon S3
- AWS MWAA: Orchestrating Databricks Workloads
- AWS Kinesis and Integrating Databricks with AWS Kinesis
- Integrating API Gateway with Kinesis

## Milestone Projects

#### 1. Complete Data Solution for a Multinational Organization
- **Objective:** Build an end-to-end data solution for a multinational organization, covering data acquisition to analysis.
- **Implementation:**
  - Write Python code to extract large datasets from multiple sources.
  - Utilize the power of Pandas for data cleaning and analysis.
  - Design a STAR-based database schema for optimized data storage and access.
  - Execute complex SQL data queries to extract valuable insights for informed decision-making.

#### 2. Pinterest's Experiment Analytics Data Pipeline
- **Objective:** Develop an analytics data pipeline for Pinterest's experiments, processing thousands of experiments daily and crunching billions of data points.
- **Implementation:**
  - Design and implement a robust data pipeline to handle large-scale experiment analytics.
  - Manage the flow of data to provide valuable insights for product improvement.
  - Tackle challenges of scale and complexity in data processing.

Feel free to explore, provide feedback, or join the journey! Your engagement is invaluable as I continue honing my skills in the intricate world of data engineering.

Cheers to knowledge, innovation, and the ever-evolving landscape of data engineering! ðŸš€


<!--
**AICoreCitizen/AICoreCitizen** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
